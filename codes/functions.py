import requests
from bs4 import BeautifulSoup
import pandas as pd
import re

def content_title(page):
    """
    Fun√ß√£o para extrair o t√≠tulo de um elemento da p√°gina da web identificado pela classe "content-head__title".

    Argumentos:
        page (objeto BeautifulSoup): O conte√∫do HTML analisado da not√≠cia.

    Retorna:
        str: O t√≠tulo extra√≠do da not√≠cia se encontrado, caso contr√°rio "t√≠tulo n√£o encontrado".
    """
    
    title = page.find("h1", class_="content-head__title")
    if title is not None:
        return title.get_text().lower()
    return "t√≠tulo n√£o encontrado"
#------------------------------------------------------------------------------------------------------------------------------------------
def content_subtitle(page):
    """
    Fun√ß√£o para extrair o subt√≠tulo de um elemento da p√°gina da web identificado pela classe "content-head__subtitle".

    Argumentos:
        page (objeto BeautifulSoup): O conte√∫do HTML analisado da not√≠cia.

    Retorna:
        str: O subt√≠tulo extra√≠do da not√≠cia se encontrado, caso contr√°rio "subt√≠tulo n√£o encontrado".
    """
    subtitle = page.find("h2", class_="content-head__subtitle")
    if subtitle is not None:
        return subtitle.get_text().lower()
    return "subt√≠tulo n√£o encontrado"
#------------------------------------------------------------------------------------------------------------------------------------------
def content_text(page):
    """
    Extrai e limpa o conte√∫do textual com a funcao `remove_text` de um elemento da p√°gina da web identificado pela classe "content-text__container".

    Argumentos:
        page (objeto BeautifulSoup): Um objeto BeautifulSoup que representa o conte√∫do HTML analisado da p√°gina da web.

    Retorna:
        str: O conte√∫do textual extra√≠do e limpo, ou "texto n√£o encontrado" se nenhum elemento correspondente for encontrado.
    """
    text = page.find_all('p', class_="content-text__container")
    if text is not None:
        text = " ".join([t.get_text().lower() for t in text])
        clean_text = remove_text(text)
        return clean_text
    return "texto n√£o encontrado"
#------------------------------------------------------------------------------------------------------------------------------------------
def content_author(page):
    """
    Fun√ß√£o para extrair o nome do autor de uma not√≠cia a partir do conte√∫do HTML fornecido (page).

    Tenta encontrar o nome do autor usando diferentes abordagens, pois a estrutura HTML pode variar entre sites.

    Argumentos:
        page (objeto BeautifulSoup): O conte√∫do HTML analisado da not√≠cia.

    Retorna:
        str: O nome do autor extra√≠do da not√≠cia se encontrado, caso contr√°rio "autor n√£o encontrado".
    """

    author = page.find("span", class_="content-publication-data__from")
    if author is not None:
        return author.get_text().lower()
    author = page.find("a", class_="multi_signatures")
    if author is not None:
        return author.get_text().lower()
    author = page.find("span", itemprop="name")
    if author is not None:
        return author.get_text().lower()
    author = page.find("p", class_="content-publication-data__from")
    if author is not None:
        return author.get("title").lower()
    return "autor n√£o encontrado"
#------------------------------------------------------------------------------------------------------------------------------------------
def content_date(page):
    """
    Fun√ß√£o para extrair a data de publica√ß√£o de um elemento da p√°gina da web identificado pelo itemprop "datePublished".

    Argumentos:
        page (objeto BeautifulSoup): O conte√∫do HTML analisado da not√≠cia.

    Retorna:
        str: A data de publica√ß√£o extra√≠da da not√≠cia se encontrada, caso contr√°rio "data n√£o encontrada".
    """
    date = page.find("time", itemprop="datePublished")
    if date is not None:
        return date.get_text()
    return "data n√£o encontrada"
#------------------------------------------------------------------------------------------------------------------------------------------
def df_news_data(lista_urls):
    """
    Coleta dados de not√≠cias a partir de uma lista de URLs e retorna um DataFrame.

    Par√¢metros:
        news_url_list (lista): Lista de URLs de not√≠cias.

    Retorno:
        DataFrame: DataFrame contendo os dados coletados das not√≠cias.
    """
    print("Inicio da raspagem de dados")
    list_url = []
    list_date = []
    list_author = []
    list_title = []  
    list_subtitle = []
    list_text = []

    for url in lista_urls:
        try:
            response = requests.get(url)
            page = BeautifulSoup(response.text, "html.parser")

            list_url.append(url)
            list_date.append(content_date(page))
            list_author.append(content_author(page))
            list_title.append(content_title(page))
            list_subtitle.append(content_subtitle(page))
            list_text.append(content_text(page))

        except Exception as e:
            print(f"Erro ao fazer scraping da URL {url}: {e}")

    print("Coleta finalizada")      
    return pd.DataFrame({"url": list_url, "date": list_date, "author": list_author, "title": list_title, "subtitle": list_subtitle, "text": list_text})
#------------------------------------------------------------------------------------------------------------------------------------------
def remove_text(text):
    """
    Fun√ß√£o para remover textos indesejados do conte√∫do da not√≠cia

    Argumentos:
        text (str): O texto da not√≠cia a ser processado.

    Retorna:
        str: O texto da not√≠cia ap√≥s a remo√ß√£o dos textos indesejados.
    """
    
    parts_to_remove = [
    r"‚úÖ siga o canal do g1 pr no whatsapp",
    r"‚úÖ siga o canal do g1 pr no telegram",
    r"v√≠deos mais assistidos do g1 pr:",
    r"leia mais not√≠cias em g1 paran√°.",
    r"v√≠deos mais assistidos do g1 pr:",
    r"leia mais:",
    r"leia mais not√≠cias em g1 paran√°.",
    r"üîéaplicativo de intelig√™ncia artificial para foto: veja 9 op√ß√µes",
    r"üì≤canal do techtudo no whatsapp: acompanhe as principais not√≠cias, tutoriais e reviews",
    r"üìù Quais os melhores chatbots para conversar com intelig√™ncia artificial?",
    r"veja no f√≥rum do techtudo",
    r"veja tamb√©m: google gemini: veja prot√≥tipo de ia que sabe e lembra de tudo",
    r"üìùcomo liberar espa√ßo no celular android? usu√°rios respondem no f√≥rum techtudo.",
    r"mais do techtudo",
    r"üì≤ acesse o canal do g1 rs no whatsapp",
    r"‚úÖ clique aqui para se inscrever no canal do g1 sp no whatsapp",
    r"üì≤ participe do canal do g1 sul de minas no whatsapp",
    r"üì≤ canal do techtudo no whatsapp: acompanhe as principais not√≠cias, tutoriais e reviews",
    r"‚úÖ clique aqui para seguir o canal de not√≠cias internacionais do g1 no whatsapp",
    r"‚úÖclique e siga o canal do g1 go no whatsapp",
    r"‚úÖ clique aqui e participe do canal do gshow no whatsapp",
    r"üéß ou√ßa o podcast ge corinthiansüéß",
    r"üîî canal do techtudo no whatsapp: acompanhe as principais not√≠cias, tutoriais e reviews",
    r""

]
    for part in parts_to_remove:
        text = re.sub(part, "", text)
    return text